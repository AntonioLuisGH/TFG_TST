\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\contentsline {listasf}{Resumen}{I}{section*.2}%
\contentsline {listasf}{Abstract}{III}{section*.4}%
\contentsline {listasf}{√çndice Abreviado}{V}{section*.5}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Organisation of the Document}{1}{section.1.1}%
\contentsline {chapter}{\numberline {2}History and State of the Art}{3}{chapter.2}%
\contentsline {section}{\numberline {2.1}Evolution of Methods for Time Series Forecasting}{3}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Traditional Methods}{3}{subsection.2.1.1}%
\contentsline {subsubsection}{Autoregressive and Moving Average Models (AR, MA, ARMA)}{3}{subsubsection*.9}%
\contentsline {subsubsection}{Autoregressive Integrated Moving Average (ARIMA) and SARIMA Models}{4}{subsubsection*.10}%
\contentsline {subsubsection}{SARIMAX models}{5}{subsubsection*.11}%
\contentsline {subsubsection}{VARMA and VARMAX Models}{5}{subsubsection*.12}%
\contentsline {subsubsection}{Simple Exponential Smoothing (SES) and Holt-Winters Exponential Smoothing (HWES)}{6}{subsubsection*.13}%
\contentsline {subsubsection}{ARCH and GARCH Models}{7}{subsubsection*.14}%
\contentsline {subsection}{\numberline {2.1.2}Modern Methods}{8}{subsection.2.1.2}%
\contentsline {subsubsection}{Recurrent Neural Networks (RNNs) and LSTMs}{8}{subsubsection*.15}%
\contentsline {subsubsection}{Residual Networks (ResNet) and Fully Convolutional Networks (FCN)}{8}{subsubsection*.16}%
\contentsline {subsubsection}{ROCKET}{9}{subsubsection*.17}%
\contentsline {subsubsection}{Matrix Factorization with DTW}{9}{subsubsection*.18}%
\contentsline {subsubsection}{XGBoost}{9}{subsubsection*.19}%
\contentsline {subsubsection}{Prophet}{10}{subsubsection*.20}%
\contentsline {subsubsection}{TS-Chief and HIVE-COTE}{10}{subsubsection*.21}%
\contentsline {section}{\numberline {2.2}Evolution of Transformers as a Method for Time Series Forecasting}{10}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Introduction of Transformers (2017)}{11}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Application to Time Series (2019)}{11}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Enhancements and New Variants (2020)}{11}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Further Innovations (2021 - 2022)}{12}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Recent Advances (2023 - 2024)}{12}{subsection.2.2.5}%
\contentsline {chapter}{\numberline {3}Transformers, Informers and Autoformers.}{15}{chapter.3}%
\contentsline {section}{\numberline {3.1}Transformer architecture}{15}{section.3.1}%
\contentsline {subsubsection}{Encoder-Decoder Structure}{16}{subsubsection*.23}%
\contentsline {subsubsection}{Self-Attention Mechanism}{17}{subsubsection*.24}%
\contentsline {section}{\numberline {3.2}Time Series Transformer}{18}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Time Series Forecasting (TSF) Problem Formulation}{18}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Embedding}{20}{subsection.3.2.2}%
\contentsline {subsubsection}{Channel Projection}{20}{subsubsection*.29}%
\contentsline {subsubsection}{Fixed Position Embedding}{20}{subsubsection*.31}%
\contentsline {subsubsection}{Local Timestamp Embedding}{20}{subsubsection*.32}%
\contentsline {subsubsection}{Global Timestamp Embedding}{20}{subsubsection*.33}%
\contentsline {subsection}{\numberline {3.2.3}Encoder}{21}{subsection.3.2.3}%
\contentsline {subsection}{\numberline {3.2.4}Decoder}{21}{subsection.3.2.4}%
\contentsline {subsection}{\numberline {3.2.5}Training Methodology}{21}{subsection.3.2.5}%
\contentsline {subsection}{\numberline {3.2.6}Probabilistic Forecasting}{22}{subsection.3.2.6}%
\contentsline {section}{\numberline {3.3}Informer}{23}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}ProbSparse Attention}{23}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Distilling}{24}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Autoformer}{24}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Decomposition Layer}{25}{subsection.3.4.1}%
\contentsline {subsubsection}{Decomposition in Autoformer}{25}{subsubsection*.38}%
\contentsline {subsection}{\numberline {3.4.2}Attention (Autocorrelation) Mechanism}{25}{subsection.3.4.2}%
\contentsline {subsubsection}{Understanding Autocorrelation}{26}{subsubsection*.40}%
\contentsline {subsubsection}{Implementing Autocorrelation with FFT}{26}{subsubsection*.42}%
\contentsline {subsubsection}{Time Delay Aggregation}{27}{subsubsection*.44}%
\contentsline {chapter}{\numberline {4}Materials and Methods}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1}Datasets}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}ORNAVERA Data Collection Device (DCD)}{29}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Available Variables}{31}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Temperature (t1)}{31}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Relative Humidity (rh1)}{31}{subsection.4.2.2}%
\contentsline {subsection}{\numberline {4.2.3}Vapor Pressure Deficit (vpd1)}{31}{subsection.4.2.3}%
\contentsline {subsection}{\numberline {4.2.4}Light Intensity (lux)}{32}{subsection.4.2.4}%
\contentsline {subsection}{\numberline {4.2.5}Soil Temperature (st1)}{32}{subsection.4.2.5}%
\contentsline {subsection}{\numberline {4.2.6}Permittivity (p1)}{32}{subsection.4.2.6}%
\contentsline {subsection}{\numberline {4.2.7}Electrical Conductivity (ec1)}{33}{subsection.4.2.7}%
\contentsline {subsection}{\numberline {4.2.8}Volumetric Water Content (vwc1)}{33}{subsection.4.2.8}%
\contentsline {subsection}{\numberline {4.2.9}Diameter (diam1)}{33}{subsection.4.2.9}%
\contentsline {subsection}{\numberline {4.2.10}Photosynthetically Active Radiation (par)}{34}{subsection.4.2.10}%
\contentsline {section}{\numberline {4.3}Variable Selection}{34}{section.4.3}%
\contentsline {section}{\numberline {4.4}Software Implementation}{35}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Anaconda and Spyder}{35}{subsection.4.4.1}%
\contentsline {subsubsection}{Anaconda}{35}{subsubsection*.61}%
\contentsline {subsubsection}{Spyder}{35}{subsubsection*.62}%
\contentsline {subsection}{\numberline {4.4.2}Google Colab}{36}{subsection.4.4.2}%
\contentsline {subsubsection}{T4 Hosted Runtime Environment}{36}{subsubsection*.63}%
\contentsline {section}{\numberline {4.5}Python Libraries}{37}{section.4.5}%
\contentsline {chapter}{\numberline {5}Experimental Design}{39}{chapter.5}%
\contentsline {section}{\numberline {5.1}Dataset Preprocessing}{39}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Structure}{39}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Signal smoothing}{40}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}Elimination of the Trend}{42}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}Elimination of NaN Values}{44}{subsection.5.1.4}%
\contentsline {subsection}{\numberline {5.1.5}Normalization of data}{44}{subsection.5.1.5}%
\contentsline {subsection}{\numberline {5.1.6}Transforming Irregular Time Series to Regular Time Series}{45}{subsection.5.1.6}%
\contentsline {section}{\numberline {5.2}Error Metrics}{45}{section.5.2}%
\contentsline {section}{\numberline {5.3}Hyperparameter Tuning}{48}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Prediction Length and Context Length}{48}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Lags Sequence}{49}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}Dropout}{50}{subsection.5.3.3}%
\contentsline {subsection}{\numberline {5.3.4}Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers}{51}{subsection.5.3.4}%
\contentsline {subsection}{\numberline {5.3.5}Batch Size and Number of Epochs}{51}{subsection.5.3.5}%
\contentsline {chapter}{\numberline {6}Experimental Results}{53}{chapter.6}%
\contentsline {section}{\numberline {6.1}Results Changing the Prediction Length and Context Length}{53}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Transformer}{53}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Informer}{55}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Autoformer}{55}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}Results Changing the Lags Sequence}{59}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Transformer}{59}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Informer}{59}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Autoformer}{61}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Results Changing the Dropout}{63}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Transformer}{63}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Informer}{63}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Autoformer}{66}{subsection.6.3.3}%
\contentsline {section}{\numberline {6.4}Results Changing the Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers}{66}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Transformer}{67}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Informer}{67}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Autoformer}{67}{subsection.6.4.3}%
\contentsline {section}{\numberline {6.5}Results Changing the Batch Size and Number of Epochs}{70}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}Transformer}{72}{subsection.6.5.1}%
\contentsline {subsection}{\numberline {6.5.2}Informer}{72}{subsection.6.5.2}%
\contentsline {subsection}{\numberline {6.5.3}Autoformer}{74}{subsection.6.5.3}%
\contentsline {chapter}{\numberline {7}Conclusions}{79}{chapter.7}%
\contentsline {section}{\numberline {7.1}Future Work}{80}{section.7.1}%
\contentsline {chapter}{Appendix \numberline {A}Codes for Designing Transformer, Informer, and Autoformer Models}{81}{Appendix.a.A}%
\contentsline {section}{\numberline {A.1}Orchestrator Code}{81}{section.a.A.1}%
\contentsline {section}{\numberline {A.2}Data Preprocessing Code}{83}{section.a.A.2}%
\contentsline {section}{\numberline {A.3}Model Definition Code}{87}{section.a.A.3}%
\contentsline {section}{\numberline {A.4}Data Loader Creation Code}{89}{section.a.A.4}%
\contentsline {section}{\numberline {A.5}Model Training Code}{90}{section.a.A.5}%
\contentsline {section}{\numberline {A.6}Model Evaluation Code}{92}{section.a.A.6}%
\mbox {}\hspace *{0pt}\par 
\contentsline {listasb}{List of Figures}{97}{section*.145}%
\contentsline {listasb}{List of Tables}{101}{section*.147}%
\contentsline {listasb}{List of Codes}{103}{section*.149}%
\contentsline {listasb}{Bibliography}{105}{section*.151}%
\contentsline {listasb}{Index}{109}{section*.153}%
\contentsline {listasb}{Glossary}{109}{section*.154}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
