\babel@toc {english}{}\relax 
\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {6.1}{\ignorespaces Mean Squared Errors (MSE) for different Transformer models obtained by varying the prediction length and context length, sorted by model}}{53}{table.caption.88}%
\contentsline {table}{\numberline {6.2}{\ignorespaces R-squared (R²) for different Transformer models obtained by varying the prediction length and context length, sorted by model}}{55}{table.caption.89}%
\contentsline {table}{\numberline {6.3}{\ignorespaces Training times for different Transformer models obtained by varying the prediction length and context length, sorted by model and training time values}}{55}{table.caption.90}%
\contentsline {table}{\numberline {6.4}{\ignorespaces Mean Squared Errors (MSE) for different Informer models obtained by varying the prediction length and context length, sorted by model}}{55}{table.caption.92}%
\contentsline {table}{\numberline {6.5}{\ignorespaces R-squared (R²) for different Informer models obtained by varying the prediction length and context length, sorted by model}}{57}{table.caption.93}%
\contentsline {table}{\numberline {6.6}{\ignorespaces Training times for different Informer models obtained by varying the prediction length and context length, sorted by model and training time values}}{57}{table.caption.94}%
\contentsline {table}{\numberline {6.7}{\ignorespaces Mean Squared Errors (MSE) for different Autoformer models obtained by varying the prediction length and context length, sorted by model}}{57}{table.caption.96}%
\contentsline {table}{\numberline {6.8}{\ignorespaces R-squared (R²) for different Autoformer models obtained by varying the prediction length and context length, sorted by model}}{57}{table.caption.97}%
\contentsline {table}{\numberline {6.9}{\ignorespaces Training times for different Autoformer models obtained by varying the prediction length and context length, sorted by model and training time values}}{59}{table.caption.98}%
\contentsline {table}{\numberline {6.10}{\ignorespaces Mean Squared Errors (MSE) for different Transformer models obtained by varying the Lags Sequence values, sorted by model}}{59}{table.caption.100}%
\contentsline {table}{\numberline {6.11}{\ignorespaces R-squared (R²) for different Transformer models obtained by varying the Lags Sequence values, sorted by model}}{59}{table.caption.101}%
\contentsline {table}{\numberline {6.12}{\ignorespaces Training times for different Transformer models obtained by varying the Lags Sequence values, sorted by model and training time values}}{61}{table.caption.102}%
\contentsline {table}{\numberline {6.13}{\ignorespaces Mean Squared Errors (MSE) for different Informer models obtained by varying the Lags Sequence values, sorted by model}}{61}{table.caption.104}%
\contentsline {table}{\numberline {6.14}{\ignorespaces R-squared (R²) for different Informer models obtained by varying the Lags Sequence values, sorted by model}}{61}{table.caption.105}%
\contentsline {table}{\numberline {6.15}{\ignorespaces Training times for different Informer models obtained by varying the Lags Sequence values, sorted by model and training time values}}{61}{table.caption.106}%
\contentsline {table}{\numberline {6.16}{\ignorespaces Mean Squared Errors (MSE) for different Autoformer models obtained by varying the Lags Sequence values, sorted by model}}{63}{table.caption.108}%
\contentsline {table}{\numberline {6.17}{\ignorespaces R-squared (R²) for different Autoformer models obtained by varying the Lags Sequence values, sorted by model}}{63}{table.caption.109}%
\contentsline {table}{\numberline {6.18}{\ignorespaces Training times for different Autoformer models obtained by varying the Lags Sequence values, sorted by model and training time values}}{63}{table.caption.110}%
\contentsline {table}{\numberline {6.19}{\ignorespaces Mean Squared Errors (MSE) for different Transformer models obtained by varying the Dropout, sorted by model}}{66}{table.caption.112}%
\contentsline {table}{\numberline {6.20}{\ignorespaces R-squared (R²) for different Transformer models obtained by varying the Dropout, sorted by model}}{66}{table.caption.113}%
\contentsline {table}{\numberline {6.21}{\ignorespaces Training times for different Transformer models obtained by varying the Dropout, sorted by model}}{66}{table.caption.114}%
\contentsline {table}{\numberline {6.22}{\ignorespaces Mean Squared Errors (MSE) for different Informer models obtained by varying the Dropout, sorted by model}}{66}{table.caption.116}%
\contentsline {table}{\numberline {6.23}{\ignorespaces R-squared (R²) for different Informer models obtained by varying the Dropout, sorted by model}}{67}{table.caption.117}%
\contentsline {table}{\numberline {6.24}{\ignorespaces Training times for different Informer models obtained by varying the Dropout, sorted by model}}{67}{table.caption.118}%
\contentsline {table}{\numberline {6.25}{\ignorespaces Mean Squared Errors (MSE) for different Autoformer models obtained by varying the Dropout, sorted by model}}{67}{table.caption.119}%
\contentsline {table}{\numberline {6.26}{\ignorespaces R-squared (R²) for different Autoformer models obtained by varying the Dropout, sorted by model}}{67}{table.caption.120}%
\contentsline {table}{\numberline {6.27}{\ignorespaces Training times for different Autoformer models obtained by varying the Dropout, sorted by model}}{68}{table.caption.121}%
\contentsline {table}{\numberline {6.28}{\ignorespaces Mean Squared Errors (MSE) for different Transformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{68}{table.caption.122}%
\contentsline {table}{\numberline {6.29}{\ignorespaces R-squared (R²) for different Transformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{68}{table.caption.123}%
\contentsline {table}{\numberline {6.30}{\ignorespaces Training times for different Transformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model and training time values}}{68}{table.caption.124}%
\contentsline {table}{\numberline {6.31}{\ignorespaces Mean Squared Errors (MSE) for different Informer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{68}{table.caption.125}%
\contentsline {table}{\numberline {6.32}{\ignorespaces R-squared (R²) for different Informer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{70}{table.caption.126}%
\contentsline {table}{\numberline {6.33}{\ignorespaces Training times for different Informer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model and training time values}}{70}{table.caption.127}%
\contentsline {table}{\numberline {6.34}{\ignorespaces Mean Squared Errors (MSE) for different Autoformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{70}{table.caption.129}%
\contentsline {table}{\numberline {6.35}{\ignorespaces R-squared (R²) for different Autoformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model}}{72}{table.caption.130}%
\contentsline {table}{\numberline {6.36}{\ignorespaces Training times for different Autoformer models obtained by varying the number of Encoder Layers, Decoder Layers, and Dimensionality of the Transformer Layers, sorted by model and training time values}}{72}{table.caption.131}%
\contentsline {table}{\numberline {6.37}{\ignorespaces Mean Squared Errors (MSE) for different Transformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{72}{table.caption.133}%
\contentsline {table}{\numberline {6.38}{\ignorespaces R-squared (R²) for different Transformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{74}{table.caption.134}%
\contentsline {table}{\numberline {6.39}{\ignorespaces Training times for different Transformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model and training time values}}{74}{table.caption.135}%
\contentsline {table}{\numberline {6.40}{\ignorespaces Mean Squared Errors (MSE) for different Informer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{74}{table.caption.137}%
\contentsline {table}{\numberline {6.41}{\ignorespaces R-squared (R²) for different Informer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{74}{table.caption.138}%
\contentsline {table}{\numberline {6.42}{\ignorespaces Training times for different Informer models obtained by varying the Batch Size and Number of Epochs values, sorted by model and training time values}}{76}{table.caption.139}%
\contentsline {table}{\numberline {6.43}{\ignorespaces Mean Squared Errors (MSE) for different Autoformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{76}{table.caption.141}%
\contentsline {table}{\numberline {6.44}{\ignorespaces R-squared (R²) for different Autoformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model}}{76}{table.caption.142}%
\contentsline {table}{\numberline {6.45}{\ignorespaces Training times for different Autoformer models obtained by varying the Batch Size and Number of Epochs values, sorted by model and training time values}}{76}{table.caption.143}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
